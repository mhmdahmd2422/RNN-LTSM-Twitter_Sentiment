{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8cTIvpMsFeg2",
        "6HLwJHdPFnXc",
        "sQuTg17jFyhN",
        "xcdApT3FF-St",
        "1v07a0ZgGytA"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbG6J53VvRpBHZAwpHuW+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhmdahmd2422/RNN-LTSM-Twitter_Sentiment/blob/main/Twitter_Sentiment(RNN~LTSM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVI0TbInDUW",
        "outputId": "1362a9ca-c670-47e4-8d7d-a1562fe87046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "8cTIvpMsFeg2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_0bbRQznngZ"
      },
      "outputs": [],
      "source": [
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Utility\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "6HLwJHdPFnXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a tf.data.Dataset\n",
        "data = pd.read_csv('gdrive/MyDrive/twitterSentiment/training.csv',encoding='latin', names = ['target','id','date','query_flag','user','tweet_text'])"
      ],
      "metadata": {
        "id": "feV8r-TaoCsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.sample(frac=1)\n",
        "# data = data[:200000]"
      ],
      "metadata": {
        "id": "hzx_J4EWoWmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x7zn9YkofCc",
        "outputId": "007a4ec4-4a8f-4eab-9de7-fd2977319866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1600000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "sQuTg17jFyhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt2yeS73pRdr",
        "outputId": "f12164ef-f46f-4784-b1bd-f904fd7eee7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the value 4 -->1 for ease of understanding.\n",
        "data['target'] = data['target'].replace(4,1)"
      ],
      "metadata": {
        "id": "Z8XEHaL0paCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of positive vs. negative tagged sentences\n",
        "positives = data['target'][data.target == 1 ]\n",
        "negatives = data['target'][data.target == 0 ]\n",
        "\n",
        "print('Total length of the data is:         {}'.format(data.shape[0]))\n",
        "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
        "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGfYH_AppTS",
        "outputId": "e4ac4040-8223-42fd-f7f3-ca1331797b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total length of the data is:         1600000\n",
            "No. of positve tagged sentences is:  800000\n",
            "No. of negative tagged sentences is: 800000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the unnecessary columns.\n",
        "data.drop(['id','date','query_flag','user'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "1Or6j3EQx-G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0H9Frc3yaqU",
        "outputId": "d32ffa3a-4f0f-4fca-a4c5-d7ab5a6c0d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target                                         tweet_text\n",
              "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1       0  is upset that he can't update his Facebook by ...\n",
              "2       0  @Kenichan I dived many times for the ball. Man...\n",
              "3       0    my whole body feels itchy and like its on fire \n",
              "4       0  @nationwideclass no, it's not behaving at all....\n",
              "5       0                      @Kwesidei not the whole crew \n",
              "6       0                                        Need a hug \n",
              "7       0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
              "8       0               @Tatiana_K nope they didn't have it \n",
              "9       0                          @twittera que me muera ? "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d8c74ab-680f-479c-848b-e3d0e344ad4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Need a hug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>@Tatiana_K nope they didn't have it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>@twittera que me muera ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d8c74ab-680f-479c-848b-e3d0e344ad4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d8c74ab-680f-479c-848b-e3d0e344ad4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d8c74ab-680f-479c-848b-e3d0e344ad4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if any null values present\n",
        "(data.isnull().sum() / len(data))*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRfKSX2CzjNW",
        "outputId": "59b6321c-e6cf-45ee-ff4a-e3bc022adb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target        0.0\n",
              "tweet_text    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convrting pandas object to a string type\n",
        "data['tweet_text'] = data['tweet_text'].astype('str')"
      ],
      "metadata": {
        "id": "Q9Uzfmt3zvUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "xcdApT3FF-St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK (Natural Language Toolkit) is a Python library used for natural language processing.**"
      ],
      "metadata": {
        "id": "QYhe_ALa5Spt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stopword = set(stopwords.words('english'))\n",
        "print(stopword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RK1s_kWz8Kz",
        "outputId": "c12a3721-61e9-4f47-a24d-c4c1db0b6560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ain', 'such', \"don't\", 'while', 'just', \"shouldn't\", 'other', 'y', 'they', 'so', 'won', 'doesn', 'didn', 're', 'before', 'each', 'too', 'yourselves', 'below', 'did', 'again', 'same', 'where', 'above', 'my', 'your', \"didn't\", 'very', 'having', 'those', 'up', 'few', 'because', 'can', \"you'll\", 'does', 'by', 'been', 'at', 'itself', 'himself', 'to', \"hadn't\", \"you've\", 'hadn', 'was', \"needn't\", 've', \"shan't\", 'yours', 'during', 'had', 'haven', 'wouldn', 'you', 'ma', 'hasn', \"should've\", 'hers', \"she's\", 'this', 'of', 'should', 'don', \"mustn't\", 'under', 'once', 'why', 't', 'i', 'about', 'own', 'all', \"aren't\", 'whom', 'will', 'shouldn', 'isn', 'than', 'who', \"wouldn't\", 'is', 'do', 'being', 'from', 'weren', 'nor', 'a', \"wasn't\", \"that'll\", 'and', 'her', 'how', 'his', 'most', 'he', \"haven't\", 'me', 'theirs', 'yourself', 'through', 'until', \"doesn't\", 'or', 'for', 'she', 'but', \"weren't\", 'are', 'd', 'couldn', 'the', 's', 'were', 'down', 'wasn', 'these', 'myself', 'after', 'be', \"isn't\", 'aren', 'an', 'ourselves', 'herself', 'against', 'between', 'mustn', \"couldn't\", 'them', 'here', \"mightn't\", 'out', 'their', 'it', \"you'd\", 'doing', 'ours', 'in', 'only', 'when', \"hasn't\", 'not', 'll', 'its', 'more', 'with', 'm', 'over', 'no', 'what', 'shan', 'have', 'off', 'now', 'as', 'any', 'am', 'into', \"it's\", 'has', 'needn', 'our', 'on', 'o', 'mightn', 'him', 'which', 'that', 'there', 'themselves', 'both', 'if', \"you're\", 'we', 'further', 'then', 'some', \"won't\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Preprocessing steps taken are:\n",
        "\n",
        "* Lower Casing: Each text is converted to lowercase.\n",
        "\n",
        "* Removing URLs: Links starting with \"http\" or \"https\" or \"www\" are replaced by \"\".\n",
        "\n",
        "* Removing Usernames: Replace @Usernames with word \"\". (eg: \"@XYZ\" to \"\")\n",
        "\n",
        "* Removing Short Words: Words with length less than 2 are removed.\n",
        "\n",
        "* Removing Stopwords: Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. (eg: \"the\", \"he\", \"have\")\n",
        "\n",
        "* Lemmatizing: Lemmatization is the process of converting a word to its base form. (e.g: “wolves” to “wolf”)\n",
        "\n",
        "[Tokenization is the process by which a large quantity of text is divided into smaller parts called tokens. These tokens are very useful for finding patterns and are considered as a base step for stemming and lemmatization.]"
      ],
      "metadata": {
        "id": "EJ7ZffwH0ViV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "userPattern = '@[^\\s]+'\n",
        "def process_tweets(tweet):\n",
        "  # Lower Casing\n",
        "    tweet = tweet.lower()\n",
        "    tweet=tweet[0:]\n",
        "    # Removing all URls\n",
        "    tweet = re.sub(urlPattern,'',tweet)\n",
        "    # Removing all @username.\n",
        "    tweet = re.sub(userPattern,'', tweet)\n",
        "    #Remove punctuations\n",
        "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "    #tokenizing words\n",
        "    tokens = word_tokenize(tweet)\n",
        "    #Removing Stop Words\n",
        "    final_tokens = [w for w in tokens if w not in stopword]\n",
        "    #reducing a word to its word stem\n",
        "    wordLemm = WordNetLemmatizer()\n",
        "    finalwords=[]\n",
        "    for w in final_tokens:\n",
        "      if len(w)>1:\n",
        "        word = wordLemm.lemmatize(w)\n",
        "        finalwords.append(word)\n",
        "    return ' '.join(finalwords)"
      ],
      "metadata": {
        "id": "QF4gB8uU0fDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_tweets'] = data['tweet_text'].apply(lambda x: process_tweets(x))\n",
        "print('Text Preprocessing complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bua9_otg1CBF",
        "outputId": "8278ecb9-41f9-4775-f34c-0af1ff4a3f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ng6YHx1P78",
        "outputId": "974c52cb-166b-4ef0-98d4-7c315cada020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target                                         tweet_text  \\\n",
              "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
              "1       0  is upset that he can't update his Facebook by ...   \n",
              "2       0  @Kenichan I dived many times for the ball. Man...   \n",
              "3       0    my whole body feels itchy and like its on fire    \n",
              "4       0  @nationwideclass no, it's not behaving at all....   \n",
              "5       0                      @Kwesidei not the whole crew    \n",
              "6       0                                        Need a hug    \n",
              "7       0  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
              "8       0               @Tatiana_K nope they didn't have it    \n",
              "9       0                          @twittera que me muera ?    \n",
              "\n",
              "                                        clean_tweets  \n",
              "0  awww thats bummer shoulda got david carr third...  \n",
              "1  upset cant update facebook texting might cry r...  \n",
              "2  dived many time ball managed save 50 rest go b...  \n",
              "3                    whole body feel itchy like fire  \n",
              "4                           behaving im mad cant see  \n",
              "5                                         whole crew  \n",
              "6                                           need hug  \n",
              "7  hey long time see yes rain bit bit lol im fine...  \n",
              "8                                         nope didnt  \n",
              "9                                          que muera  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ff7637e-0687-41c2-9627-8aa2e8301c77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>clean_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>awww thats bummer shoulda got david carr third...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>upset cant update facebook texting might cry r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>dived many time ball managed save 50 rest go b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>behaving im mad cant see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Need a hug</td>\n",
              "      <td>need hug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "      <td>hey long time see yes rain bit bit lol im fine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>@Tatiana_K nope they didn't have it</td>\n",
              "      <td>nope didnt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>@twittera que me muera ?</td>\n",
              "      <td>que muera</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ff7637e-0687-41c2-9627-8aa2e8301c77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ff7637e-0687-41c2-9627-8aa2e8301c77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ff7637e-0687-41c2-9627-8aa2e8301c77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the unnecessary columns.\n",
        "data.drop(['tweet_text'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "QaqWoxgUKPdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer object, which can be used to covert any word into a Key in dictionary (number).\n",
        "\n",
        "**tokenizer** create tokens for every word in the data corpus and map them to a index using dictionary.\n",
        "\n",
        "**word_index** contains the index for each word\n",
        "\n",
        "**vocab_size** represents the total number of word in the data corpus\n",
        "\n",
        "Since we are going to build a sequence model. We should feed in a sequence of numbers to it. And also we should ensure there is no variance in input shapes of sequences. It all should be of same lenght. But texts in tweets have different count of words in it. To avoid this, we seek a little help from pad_sequence to do our job. It will make all the sequence in one constant lengt[MAX_SEQUENCE_LENGTH]\n",
        "\n",
        "***!!! Better than masking to handle the variable sequence lengths!!! ***"
      ],
      "metadata": {
        "id": "BJlmRPvyOS1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data.clean_tweets)\n",
        "sequences = tokenizer.texts_to_sequences(data.clean_tweets)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma--UVLwWZqK",
        "outputId": "ebc983ba-239c-48f8-9ff4-ae7aca8d2fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...  701 1705    2]\n",
            " [   0    0    0 ...   11  175 1049]\n",
            " [   0    0    0 ...  360    6 2960]\n",
            " ...\n",
            " [   0    0    0 ...  124  498 1657]\n",
            " [   0    0    0 ...  394 4667   13]\n",
            " [   0    0    0 ...    0    0   56]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train - validation and test"
      ],
      "metadata": {
        "id": "1v07a0ZgGytA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val_test, y_train, y_val_test = train_test_split(tweets, data.target.values, test_size=0.2, random_state=101)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=101)\n",
        "print(\"X_train\", X_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print()\n",
        "print(\"X_val\", X_val.shape)\n",
        "print(\"y_val\", y_val.shape)\n",
        "print()\n",
        "print(\"X_test\", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0i9sj5nElxd",
        "outputId": "9ea83cb9-e432-425d-d1c6-57573afc05b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (1280000, 200)\n",
            "y_train (1280000,)\n",
            "\n",
            "X_val (160000, 200)\n",
            "y_val (160000,)\n",
            "\n",
            "X_test (160000, 200)\n",
            "y_test (160000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "3x8ZoVB1HEPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 128))\n",
        "model.add(layers.SimpleRNN(64,dropout=0.5))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=3,validation_data=(X_val, y_val), validation_steps=30)"
      ],
      "metadata": {
        "id": "H6suL0-rsHxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b08e60-8930-49d6-9263-90bc44a78b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "40000/40000 [==============================] - 3446s 86ms/step - loss: 0.4807 - accuracy: 0.7685 - val_loss: 0.4642 - val_accuracy: 0.7795\n",
            "Epoch 2/3\n",
            "40000/40000 [==============================] - 3452s 86ms/step - loss: 0.4632 - accuracy: 0.7800 - val_loss: 0.4629 - val_accuracy: 0.7809\n",
            "Epoch 3/3\n",
            "40000/40000 [==============================] - 3451s 86ms/step - loss: 0.4602 - accuracy: 0.7817 - val_loss: 0.4617 - val_accuracy: 0.7791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_words, 128))\n",
        "model2.add(layers.LSTM(64,dropout=0.5))\n",
        "model2.add(layers.Dense(16, activation='relu'))\n",
        "model2.add(layers.Dense(8, activation='relu'))\n",
        "model2.add(layers.Dense(1,activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history2 = model2.fit(X_train, y_train, epochs=3,validation_data=(X_val, y_val), validation_steps=30)"
      ],
      "metadata": {
        "id": "FS4GbOPaU8wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8281d75a-f19b-4be3-a9b8-3b76b6084911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "40000/40000 [==============================] - 6172s 154ms/step - loss: 0.4680 - accuracy: 0.7762 - val_loss: 0.4523 - val_accuracy: 0.7859\n",
            "Epoch 2/3\n",
            "40000/40000 [==============================] - 6159s 154ms/step - loss: 0.4490 - accuracy: 0.7879 - val_loss: 0.4472 - val_accuracy: 0.7885\n",
            "Epoch 3/3\n",
            " 9651/40000 [======>.......................] - ETA: 1:15:57 - loss: 0.4422 - accuracy: 0.7923"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluating"
      ],
      "metadata": {
        "id": "Drri_vWGHdo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n\\n=========RNN Evaluation On Test Set=========')\n",
        "results_RNN = model.evaluate(X_test, y_test)\n",
        "print('\\n\\n')\n",
        "print('\\n\\n=========LSTM Evaluation On Test Set=========')\n",
        "results_LSTM = model2.evaluate(X_test, y_test)\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "id": "5BUZvLZqDiEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:<30} {:<20} {:<20}'.format('', 'Loss', 'Accuracy'))\n",
        "print('{:<30} {:<20.4f} {:<20.4f}'.format('RNN', results_RNN[0], results_RNN[1]))\n",
        "print('{:<30} {:<20.4f} {:<20.4f}'.format('LSTM', results_LSTM[0], results_LSTM[1]))"
      ],
      "metadata": {
        "id": "oWQKvaHIEmsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_metrics(history):\n",
        "  # plot el accuracy\n",
        "  plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
        "  plt.plot(history.history[\"val_accuracy\"], label=\"Val. Acc\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Acc.\")\n",
        "  plt.show()\n",
        "  print('\\n\\n')\n",
        "# plot el loss\n",
        "  plt.plot(history.history[\"loss\"], label=\"Train loss\")\n",
        "  plt.plot(history.history[\"val_loss\"], label=\"Val. loss\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zj0vwQB8B0SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n\\n=========RNN Metrics Plot=========')\n",
        "compare_metrics(history)\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "id": "zQsTqOHRE8vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n\\n=========LSTM Metrics Plot=========')\n",
        "compare_metrics(history2)\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "id": "HMRiEC_dFBU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}